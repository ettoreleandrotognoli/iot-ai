{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ettore/py3-venv/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "TIMESTAMP = int(time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos os dados já embaralhados divididos em train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos as entradas pra `float` (pra poder manipular), adicionamos a dimensão do canal e pré-tratamos\n",
    "Como temos um intervalo definido de entrada [0, 255], simplesmente mudamos a escala para [0, 1], o que é bem comum de se fazer em imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos os labels pra one-hot encoding (vetor 10-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de entrada (compatível com a forma de x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = entry = Input(shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Conv2D(32, kernel_size=3, strides=1)(out)\n",
    "out = Activation('relu')(out)\n",
    "out = MaxPool2D()(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos o tensor em um vetor unidimensional. Isso  é necessário para podermos aplicar uma camada densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Flatten()(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada intermediária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(20)(out)\n",
    "out = Activation('relu')(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de saída com 10 neurônios, cada um responsável por um dígito e aplicação do softmax para obtermos uma distribuição de probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(10)(out)\n",
    "out = Activation('softmax')(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do modelo em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(entry, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos a descrição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                108180    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 108,710\n",
      "Trainable params: 108,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do custo e da otimização\n",
    "Custo é a cross-entropia entre saída e resposta\n",
    "Otimização é a descida de gradientes estocástica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.1501 - acc: 0.9553 - val_loss: 0.1114 - val_acc: 0.9661\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.0956 - acc: 0.9724 - val_loss: 0.0875 - val_acc: 0.9742\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.0735 - acc: 0.9780 - val_loss: 0.0749 - val_acc: 0.9763\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.0605 - acc: 0.9821 - val_loss: 0.0606 - val_acc: 0.9801\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.0521 - acc: 0.9842 - val_loss: 0.0573 - val_acc: 0.9824\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0447 - acc: 0.9868 - val_loss: 0.0558 - val_acc: 0.9809\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0404 - acc: 0.9873 - val_loss: 0.0538 - val_acc: 0.9835\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.0359 - acc: 0.9890 - val_loss: 0.0527 - val_acc: 0.9832\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.0311 - acc: 0.9908 - val_loss: 0.0503 - val_acc: 0.9836\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.0279 - acc: 0.9920 - val_loss: 0.0545 - val_acc: 0.9823\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0540 - val_acc: 0.9827\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0546 - val_acc: 0.9833\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.0202 - acc: 0.9939 - val_loss: 0.0568 - val_acc: 0.9819\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 31s 520us/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0494 - val_acc: 0.9853\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 31s 511us/step - loss: 0.0158 - acc: 0.9954 - val_loss: 0.0521 - val_acc: 0.9849\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0133 - acc: 0.9962 - val_loss: 0.0553 - val_acc: 0.9844\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0536 - val_acc: 0.9845\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.0104 - acc: 0.9972 - val_loss: 0.0606 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0549 - val_acc: 0.9845\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0620 - val_acc: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56c9126dd8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=60,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('save/mnist.{epoch:02d}.h5'),\n",
    "        TensorBoard(log_dir='logs/mnist_{}'.format(TIMESTAMP), histogram_freq=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(len(x_test))\n",
    "image, answer = x_test[i], y_test[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria a entrada e infere a saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rede diz 6\n",
      "Gabarito 6\n"
     ]
    }
   ],
   "source": [
    "x = np.reshape(image, (1, 28, 28, 1))\n",
    "y = net.predict(x, verbose=0)[0]\n",
    "\n",
    "plt.imshow(x[0, ..., 0], cmap='gray')\n",
    "plt.show()\n",
    "print('A rede diz', np.argmax(y))\n",
    "print('Gabarito', np.argmax(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
